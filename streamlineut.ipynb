{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNbk6d89fZbIXYZjqL1QgUY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Siddu123421/AI-Resume-Ranking-system/blob/main/streamlineut.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import subprocess\n"
      ],
      "metadata": {
        "id": "CVUkQ54Wl-vz"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subprocess.Popen([\"streamlit\", \"run\", \"editable_resume_ranking_system.py\", \"--server.port\", \"8501\"])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rzvru0hVavlZ",
        "outputId": "dd898fe6-e697-464e-d772-e94223d61a85"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Popen: returncode: None args: ['streamlit', 'run', 'editable_resume_ranking...>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!ls /content\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RmpHTcOqj0r9",
        "outputId": "69f4ea6c-5e30-40e7-9db9-4a623d38e11c"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A_Logo_Image_IntelliHire.png\t   resume_ranking_system.py\n",
            "editable_resume_ranking_system.py  sample_data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logo_path = \"/content/A_Logo_Image_IntelliHire.png\"\n"
      ],
      "metadata": {
        "id": "NecSCV9Ch1xo"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile resume_ranking_system.py\n",
        "# ---------- Resume Ranking Streamlit App (Full Version) ----------\n",
        "import streamlit as st\n",
        "import pandas as pd, os, re\n",
        "from pypdf import PdfReader\n",
        "from docx import Document\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import spacy\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------- Load models ----------\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# ---------- Helper functions ----------\n",
        "def clean_text(t):\n",
        "    return re.sub(r\"\\s+\", \" \", t.replace(\"\\x00\", \" \")).strip()\n",
        "\n",
        "def read_pdf(path):\n",
        "    reader = PdfReader(path)\n",
        "    return \" \".join([p.extract_text() or \"\" for p in reader.pages])\n",
        "\n",
        "def read_docx(path):\n",
        "    doc = Document(path)\n",
        "    return \" \".join(p.text for p in doc.paragraphs)\n",
        "\n",
        "def read_resume(path):\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext == \".pdf\":\n",
        "        return clean_text(read_pdf(path))\n",
        "    if ext == \".docx\":\n",
        "        return clean_text(read_docx(path))\n",
        "    if ext == \".txt\":\n",
        "        return clean_text(open(path, \"r\", errors=\"ignore\").read())\n",
        "    return \"\"\n",
        "\n",
        "def extract_skills(text):\n",
        "    skills = [\n",
        "        \"python\",\"java\",\"c++\",\"sql\",\"git\",\"linux\",\"docker\",\"aws\",\"azure\",\"gcp\",\n",
        "        \"pandas\",\"numpy\",\"scikit-learn\",\"tensorflow\",\"pytorch\",\"keras\",\"nlp\",\n",
        "        \"opencv\",\"power bi\",\"tableau\"\n",
        "    ]\n",
        "    found = [s for s in skills if re.search(rf\"\\b{s}\\b\", text.lower())]\n",
        "    return list(set(found))\n",
        "\n",
        "def degree_score(text):\n",
        "    t = text.lower()\n",
        "    if \"phd\" in t: return 1.0\n",
        "    if any(x in t for x in [\"m.tech\",\"mtech\",\"masters\",\"m.sc\",\"msc\"]): return 0.8\n",
        "    if any(x in t for x in [\"b.tech\",\"btech\",\"b.e\",\"be \"]): return 0.6\n",
        "    if \"bsc\" in t: return 0.4\n",
        "    return 0.0\n",
        "\n",
        "def extract_years(text):\n",
        "    yrs = re.findall(r\"(\\d{1,2})\\s*\\+?\\s*(?:years|yrs|year)\", text.lower())\n",
        "    return int(max(yrs)) if yrs else 0\n",
        "\n",
        "# ---------- Compute Scores ----------\n",
        "def compute_score(job_desc, resume_text):\n",
        "    job_vec = model.encode(job_desc, convert_to_tensor=True)\n",
        "    res_vec = model.encode(resume_text, convert_to_tensor=True)\n",
        "    sim = float(util.cos_sim(job_vec, res_vec).cpu().numpy()[0][0])\n",
        "    sim = (sim + 1)/2\n",
        "\n",
        "    job_skills = set(extract_skills(job_desc))\n",
        "    res_skills = set(extract_skills(resume_text))\n",
        "    skill_fit = len(job_skills & res_skills)/len(job_skills) if job_skills else 0\n",
        "    deg = degree_score(resume_text)\n",
        "    years = extract_years(resume_text)\n",
        "    yrs_norm = min(1.0, years/8.0)\n",
        "\n",
        "    final = 0.55*sim + 0.25*skill_fit + 0.12*yrs_norm + 0.08*deg\n",
        "    return sim, skill_fit, yrs_norm, deg, final, res_skills\n",
        "\n",
        "# ---------- Streamlit UI ----------\n",
        "st.set_page_config(page_title=\"AI Resume Ranking System\", page_icon=\"ü§ñ\", layout=\"wide\")\n",
        "st.title(\"ü§ñ AI Resume Ranking System (Advanced)\")\n",
        "\n",
        "st.write(\"Upload a job description and resume files to get ranking, analysis, and skill insights.\")\n",
        "\n",
        "job_desc = st.text_area(\"Paste Job Description\", height=200, placeholder=\"Enter or paste job description here...\")\n",
        "\n",
        "uploaded_files = st.file_uploader(\n",
        "    \"Upload Resume Files (.pdf, .docx, .txt)\",\n",
        "    accept_multiple_files=True\n",
        ")\n",
        "\n",
        "if st.button(\"Rank Resumes\"):\n",
        "    if not job_desc.strip():\n",
        "        st.warning(\"Please enter a job description.\")\n",
        "    elif not uploaded_files:\n",
        "        st.warning(\"Please upload at least one resume file.\")\n",
        "    else:\n",
        "        results = []\n",
        "        all_skills = []\n",
        "        for f in uploaded_files:\n",
        "            with open(f.name, \"wb\") as out:\n",
        "                out.write(f.read())\n",
        "            text = read_resume(f.name)\n",
        "            sim, skill_fit, yrs, deg, final, res_skills = compute_score(job_desc, text)\n",
        "            all_skills.extend(res_skills)\n",
        "            results.append({\n",
        "                \"File\": f.name,\n",
        "                \"Semantic_Similarity\": round(sim,4),\n",
        "                \"Skill_Fit\": round(skill_fit,4),\n",
        "                \"Years_of_Experience\": round(yrs*8,1),\n",
        "                \"Degree_Score\": round(deg,3),\n",
        "                \"Final_Score\": round(final,4),\n",
        "                \"Matched_Skills\": \", \".join(sorted(res_skills))\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(results).sort_values(\"Final_Score\", ascending=False).reset_index(drop=True)\n",
        "        st.success(\"Ranking Completed ‚úÖ\")\n",
        "        st.dataframe(df)\n",
        "\n",
        "        csv = df.to_csv(index=False).encode(\"utf-8\")\n",
        "        st.download_button(\"Download Results CSV\", data=csv, file_name=\"ranked_resumes.csv\", mime=\"text/csv\")\n",
        "\n",
        "        # ---------- WordCloud ----------\n",
        "        if all_skills:\n",
        "            st.subheader(\"üß† Skill Frequency WordCloud\")\n",
        "            text_wc = \" \".join(all_skills)\n",
        "            wc = WordCloud(width=800, height=400, background_color=\"white\").generate(text_wc)\n",
        "            fig, ax = plt.subplots(figsize=(10,5))\n",
        "            ax.imshow(wc, interpolation=\"bilinear\")\n",
        "            ax.axis(\"off\")\n",
        "            st.pyplot(fig)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JHNoIcNlh4c4",
        "outputId": "86293bcf-22b6-470a-c20b-66576b2abb5c"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting resume_ranking_system.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pyngrok\n"
      ],
      "metadata": {
        "id": "iq9eHiQ3iToX"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q streamlit pyngrok sentence-transformers spacy pypdf python-docx wordcloud matplotlib\n",
        "!python -m spacy download en_core_web_sm -q\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mg7eLaSbi0jo",
        "outputId": "6e32e736-37fb-4c0c-c6da-ad059de5697a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m70.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[38;5;2m‚úî Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m‚ö† Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile resume_ranking_system.py\n",
        "import streamlit as st\n",
        "st.title(\"‚úÖ Streamlit Check\")\n",
        "st.write(\"If you see this, Streamlit is running correctly in Colab.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QecdEsC-kkdt",
        "outputId": "d99bd291-28aa-4e6a-e585-9782a5765e19"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting resume_ranking_system.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading, time, subprocess\n",
        "\n",
        "ngrok.set_auth_token(\"354KalSeNvIr47WQUCSoi9WDAwD_Me2zhpjuUUF1JWGREc2F\")\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.Popen([\"streamlit\", \"run\", \"resume_ranking_system.py\", \"--server.port\", \"8501\"])\n",
        "\n",
        "threading.Thread(target=run_streamlit).start()\n",
        "time.sleep(10)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"üåê Your app is live at:\", public_url.public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kScKS8szkr2V",
        "outputId": "3f4d7927-813d-47a7-ceb4-35148644ab54"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Your app is live at: https://bryce-nonentailed-outbully.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile resume_ranking_system.py\n",
        "# ---------- Resume Ranking Streamlit App (Full Version) ----------\n",
        "import streamlit as st\n",
        "import pandas as pd, os, re\n",
        "from pypdf import PdfReader\n",
        "from docx import Document\n",
        "from sentence_transformers import SentenceTransformer, util\n",
        "import spacy\n",
        "from wordcloud import WordCloud\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# ---------- Load models ----------\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
        "\n",
        "# ---------- Helper functions ----------\n",
        "def clean_text(t):\n",
        "    return re.sub(r\"\\s+\", \" \", t.replace(\"\\x00\", \" \")).strip()\n",
        "\n",
        "def read_pdf(path):\n",
        "    reader = PdfReader(path)\n",
        "    return \" \".join([p.extract_text() or \"\" for p in reader.pages])\n",
        "\n",
        "def read_docx(path):\n",
        "    doc = Document(path)\n",
        "    return \" \".join(p.text for p in doc.paragraphs)\n",
        "\n",
        "def read_resume(path):\n",
        "    ext = os.path.splitext(path)[1].lower()\n",
        "    if ext == \".pdf\":\n",
        "        return clean_text(read_pdf(path))\n",
        "    if ext == \".docx\":\n",
        "        return clean_text(read_docx(path))\n",
        "    if ext == \".txt\":\n",
        "        return clean_text(open(path, \"r\", errors=\"ignore\").read())\n",
        "    return \"\"\n",
        "\n",
        "def extract_skills(text):\n",
        "    skills = [\n",
        "        \"python\",\"java\",\"c++\",\"sql\",\"git\",\"linux\",\"docker\",\"aws\",\"azure\",\"gcp\",\n",
        "        \"pandas\",\"numpy\",\"scikit-learn\",\"tensorflow\",\"pytorch\",\"keras\",\"nlp\",\n",
        "        \"opencv\",\"power bi\",\"tableau\"\n",
        "    ]\n",
        "    found = [s for s in skills if re.search(rf\"\\b{s}\\b\", text.lower())]\n",
        "    return list(set(found))\n",
        "\n",
        "def degree_score(text):\n",
        "    t = text.lower()\n",
        "    if \"phd\" in t: return 1.0\n",
        "    if any(x in t for x in [\"m.tech\",\"mtech\",\"masters\",\"m.sc\",\"msc\"]): return 0.8\n",
        "    if any(x in t for x in [\"b.tech\",\"btech\",\"b.e\",\"be \"]): return 0.6\n",
        "    if \"bsc\" in t: return 0.4\n",
        "    return 0.0\n",
        "\n",
        "def extract_years(text):\n",
        "    yrs = re.findall(r\"(\\d{1,2})\\s*\\+?\\s*(?:years|yrs|year)\", text.lower())\n",
        "    return int(max(yrs)) if yrs else 0\n",
        "\n",
        "# ---------- Compute Scores ----------\n",
        "def compute_score(job_desc, resume_text):\n",
        "    job_vec = model.encode(job_desc, convert_to_tensor=True)\n",
        "    res_vec = model.encode(resume_text, convert_to_tensor=True)\n",
        "    sim = float(util.cos_sim(job_vec, res_vec).cpu().numpy()[0][0])\n",
        "    sim = (sim + 1)/2\n",
        "\n",
        "    job_skills = set(extract_skills(job_desc))\n",
        "    res_skills = set(extract_skills(resume_text))\n",
        "    skill_fit = len(job_skills & res_skills)/len(job_skills) if job_skills else 0\n",
        "    deg = degree_score(resume_text)\n",
        "    years = extract_years(resume_text)\n",
        "    yrs_norm = min(1.0, years/8.0)\n",
        "\n",
        "    final = 0.55*sim + 0.25*skill_fit + 0.12*yrs_norm + 0.08*deg\n",
        "    return sim, skill_fit, yrs_norm, deg, final, res_skills\n",
        "\n",
        "# ---------- Streamlit UI ----------\n",
        "st.set_page_config(page_title=\"AI Resume Ranking System\", page_icon=\"ü§ñ\", layout=\"wide\")\n",
        "st.title(\"ü§ñ AI Resume Ranking System (Advanced)\")\n",
        "\n",
        "st.write(\"Upload a job description and resume files to get ranking, analysis, and skill insights.\")\n",
        "\n",
        "job_desc = st.text_area(\"Paste Job Description\", height=200, placeholder=\"Enter or paste job description here...\")\n",
        "\n",
        "uploaded_files = st.file_uploader(\n",
        "    \"Upload Resume Files (.pdf, .docx, .txt)\",\n",
        "    accept_multiple_files=True\n",
        ")\n",
        "\n",
        "if st.button(\"Rank Resumes\"):\n",
        "    if not job_desc.strip():\n",
        "        st.warning(\"Please enter a job description.\")\n",
        "    elif not uploaded_files:\n",
        "        st.warning(\"Please upload at least one resume file.\")\n",
        "    else:\n",
        "        results = []\n",
        "        all_skills = []\n",
        "        for f in uploaded_files:\n",
        "            with open(f.name, \"wb\") as out:\n",
        "                out.write(f.read())\n",
        "            text = read_resume(f.name)\n",
        "            sim, skill_fit, yrs, deg, final, res_skills = compute_score(job_desc, text)\n",
        "            all_skills.extend(res_skills)\n",
        "            results.append({\n",
        "                \"File\": f.name,\n",
        "                \"Semantic_Similarity\": round(sim,4),\n",
        "                \"Skill_Fit\": round(skill_fit,4),\n",
        "                \"Years_of_Experience\": round(yrs*8,1),\n",
        "                \"Degree_Score\": round(deg,3),\n",
        "                \"Final_Score\": round(final,4),\n",
        "                \"Matched_Skills\": \", \".join(sorted(res_skills))\n",
        "            })\n",
        "\n",
        "        df = pd.DataFrame(results).sort_values(\"Final_Score\", ascending=False).reset_index(drop=True)\n",
        "        st.success(\"Ranking Completed ‚úÖ\")\n",
        "        st.dataframe(df)\n",
        "\n",
        "        csv = df.to_csv(index=False).encode(\"utf-8\")\n",
        "        st.download_button(\"Download Results CSV\", data=csv, file_name=\"ranked_resumes.csv\", mime=\"text/csv\")\n",
        "\n",
        "        # ---------- WordCloud ----------\n",
        "        if all_skills:\n",
        "            st.subheader(\"üß† Skill Frequency WordCloud\")\n",
        "            text_wc = \" \".join(all_skills)\n",
        "            wc = WordCloud(width=800, height=400, background_color=\"white\").generate(text_wc)\n",
        "            fig, ax = plt.subplots(figsize=(10,5))\n",
        "            ax.imshow(wc, interpolation=\"bilinear\")\n",
        "            ax.axis(\"off\")\n",
        "            st.pyplot(fig)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dmOYUt0tlJKI",
        "outputId": "91cf3876-1f69-4848-8387-f954daf7e9f7"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting resume_ranking_system.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyngrok import ngrok\n",
        "import threading, time, subprocess\n",
        "\n",
        "ngrok.set_auth_token(\"354KalSeNvIr47WQUCSoi9WDAwD_Me2zhpjuUUF1JWGREc2F\")\n",
        "\n",
        "def run_streamlit():\n",
        "    subprocess.Popen([\"streamlit\", \"run\", \"resume_ranking_system.py\", \"--server.port\", \"8501\"])\n",
        "\n",
        "threading.Thread(target=run_streamlit).start()\n",
        "time.sleep(10)\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"üåê Your app is live at:\", public_url.public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlV9yPh5h-Du",
        "outputId": "0779f42a-07f5-46c8-e14c-3f31243033b2"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üåê Your app is live at: https://bryce-nonentailed-outbully.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q fpdf"
      ],
      "metadata": {
        "id": "jiGBsvInmkuZ"
      },
      "execution_count": 21,
      "outputs": []
    }
  ]
}